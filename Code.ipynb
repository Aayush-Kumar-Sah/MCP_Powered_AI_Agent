{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae0e9683",
   "metadata": {},
   "source": [
    "### We begin by defining install_packages function that specifies all the dependencies required for our tutorial, including mcp-agent, Gemini, and supporting libraries. We then run this function to automatically install each package, ensuring our environment is fully prepared before proceeding further"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee926dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "import os\n",
    "from typing import Dict, List, Any, Optional, Union\n",
    "import json\n",
    "import asyncio\n",
    "from datetime import datetime\n",
    "import logging\n",
    "\n",
    "\n",
    "def install_packages():\n",
    "   \"\"\"Install required packages for the tutorial\"\"\"\n",
    "   packages = [\n",
    "       'mcp',\n",
    "       'google-generativeai',\n",
    "       'requests',\n",
    "       'beautifulsoup4',\n",
    "       'matplotlib',\n",
    "       'numpy',\n",
    "       'websockets',\n",
    "       'pydantic'\n",
    "   ]\n",
    "  \n",
    "   for package in packages:\n",
    "       try:\n",
    "           subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "           print(f\"‚úÖ Successfully installed {package}\")\n",
    "       except subprocess.CalledProcessError as e:\n",
    "           print(f\"‚ùå Failed to install {package}: {e}\")\n",
    "\n",
    "\n",
    "install_packages()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50aeb049",
   "metadata": {},
   "source": [
    "### We import all the core libraries we need, from Gemini and web scraping utilities to visualization and numerical tools. We also bring in the mcp-agent modules for protocol communication and configure logging so that we can track our agent‚Äôs execution flow in real time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42742a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from mcp import ClientSession, StdioServerParameters\n",
    "from mcp.client.stdio import stdio_client\n",
    "from mcp.types import TextContent, ImageContent, EmbeddedResource\n",
    "import mcp.types as types\n",
    "\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad119b34",
   "metadata": {},
   "source": [
    "### We design the MCPToolServer class that defines and manages all the tools our agent can use, including web search, data analysis, code execution, and weather information. We implement async methods for each tool, enabling the agent to perform the requested operation, such as fetching Wikipedia text, generating visualizations, executing Python snippets, or simulating weather data, and return the results in a structured format. This structure makes our MCP server modular and easily extensible for adding more tools in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90c8c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MCPToolServer:\n",
    "   \"\"\"MCP Server that provides tools for the AI agent\"\"\"\n",
    "  \n",
    "   def __init__(self):\n",
    "       self.tools = {\n",
    "           \"web_search\": {\n",
    "               \"name\": \"web_search\",\n",
    "               \"description\": \"Search the web for information\",\n",
    "               \"inputSchema\": {\n",
    "                   \"type\": \"object\",\n",
    "                   \"properties\": {\n",
    "                       \"query\": {\"type\": \"string\", \"description\": \"Search query\"}\n",
    "                   },\n",
    "                   \"required\": [\"query\"]\n",
    "               }\n",
    "           },\n",
    "           \"data_analysis\": {\n",
    "               \"name\": \"data_analysis\",\n",
    "               \"description\": \"Analyze data and create visualizations\",\n",
    "               \"inputSchema\": {\n",
    "                   \"type\": \"object\",\n",
    "                   \"properties\": {\n",
    "                       \"data_type\": {\"type\": \"string\", \"description\": \"Type of analysis\"},\n",
    "                       \"parameters\": {\"type\": \"object\", \"description\": \"Analysis parameters\"}\n",
    "                   },\n",
    "                   \"required\": [\"data_type\"]\n",
    "               }\n",
    "           },\n",
    "           \"code_execution\": {\n",
    "               \"name\": \"code_execution\",\n",
    "               \"description\": \"Execute or generate code\",\n",
    "               \"inputSchema\": {\n",
    "                   \"type\": \"object\",\n",
    "                   \"properties\": {\n",
    "                       \"language\": {\"type\": \"string\", \"description\": \"Programming language\"},\n",
    "                       \"task\": {\"type\": \"string\", \"description\": \"Code task description\"}\n",
    "                   },\n",
    "                   \"required\": [\"language\", \"task\"]\n",
    "               }\n",
    "           },\n",
    "           \"weather_info\": {\n",
    "               \"name\": \"weather_info\",\n",
    "               \"description\": \"Get weather information\",\n",
    "               \"inputSchema\": {\n",
    "                   \"type\": \"object\",\n",
    "                   \"properties\": {\n",
    "                       \"location\": {\"type\": \"string\", \"description\": \"Location for weather\"}\n",
    "                   },\n",
    "                   \"required\": [\"location\"]\n",
    "               }\n",
    "           }\n",
    "       }\n",
    "  \n",
    "   async def list_tools(self) -> List[types.Tool]:\n",
    "       \"\"\"Return list of available tools\"\"\"\n",
    "       return [types.Tool(**tool) for tool in self.tools.values()]\n",
    "  \n",
    "   async def call_tool(self, name: str, arguments: Dict[str, Any]) -> List[types.TextContent]:\n",
    "       \"\"\"Execute a tool and return results\"\"\"\n",
    "       if name == \"web_search\":\n",
    "           return await self._web_search(arguments.get(\"query\", \"\"))\n",
    "       elif name == \"data_analysis\":\n",
    "           return await self._data_analysis(arguments.get(\"data_type\", \"\"), arguments.get(\"parameters\", {}))\n",
    "       elif name == \"code_execution\":\n",
    "           return await self._code_execution(arguments.get(\"language\", \"\"), arguments.get(\"task\", \"\"))\n",
    "       elif name == \"weather_info\":\n",
    "           return await self._weather_info(arguments.get(\"location\", \"\"))\n",
    "       else:\n",
    "           return [types.TextContent(type=\"text\", text=f\"Unknown tool: {name}\")]\n",
    "  \n",
    "   async def _web_search(self, query: str) -> List[types.TextContent]:\n",
    "       \"\"\"Perform web search\"\"\"\n",
    "       try:\n",
    "           search_url = f\"https://www.wikipedia.org/wiki/Special:Search?search={query.replace(' ', '%20')}\"\n",
    "           headers = {'User-Agent': 'Mozilla/5.0 (compatible; MCP Agent)'}\n",
    "          \n",
    "           response = requests.get(search_url, headers=headers, timeout=10)\n",
    "           if response.status_code == 200:\n",
    "               soup = BeautifulSoup(response.content, 'html.parser')\n",
    "               paragraphs = soup.find_all('p')[:3]\n",
    "               content = \"n\".join([p.get_text().strip() for p in paragraphs if p.get_text().strip()])\n",
    "              \n",
    "               result = f\"üîç Web search results for '{query}':nn{content[:500]}...\"\n",
    "           else:\n",
    "               result = f\"‚ùå Web search failed with status: {response.status_code}\"\n",
    "              \n",
    "       except Exception as e:\n",
    "           result = f\"‚ùå Web search error: {str(e)}\"\n",
    "      \n",
    "       return [types.TextContent(type=\"text\", text=result)]\n",
    "  \n",
    "   async def _data_analysis(self, data_type: str, parameters: Dict) -> List[types.TextContent]:\n",
    "       \"\"\"Perform data analysis\"\"\"\n",
    "       try:\n",
    "           if \"sine\" in data_type.lower() or \"wave\" in data_type.lower():\n",
    "               x = np.linspace(0, 4*np.pi, 100)\n",
    "               y = np.sin(x) + np.random.normal(0, 0.1, 100)\n",
    "               title = \"Sine Wave Analysis\"\n",
    "           else:\n",
    "               x = np.random.normal(0, 1, 100)\n",
    "               y = np.random.normal(0, 1, 100)\n",
    "               title = \"Random Data Analysis\"\n",
    "          \n",
    "           plt.figure(figsize=(10, 6))\n",
    "           plt.scatter(x, y, alpha=0.6)\n",
    "           plt.title(f\"üìä {title}\")\n",
    "           plt.xlabel(\"X Values\")\n",
    "           plt.ylabel(\"Y Values\")\n",
    "           plt.grid(True, alpha=0.3)\n",
    "           plt.show()\n",
    "          \n",
    "           stats = {\n",
    "               \"mean_x\": np.mean(x),\n",
    "               \"mean_y\": np.mean(y),\n",
    "               \"std_x\": np.std(x),\n",
    "               \"std_y\": np.std(y),\n",
    "               \"correlation\": np.corrcoef(x, y)[0,1]\n",
    "           }\n",
    "          \n",
    "           result = f\"üìä Data Analysis Results:n\"\n",
    "           result += f\"Dataset: {title}n\"\n",
    "           result += f\"Sample size: {len(x)}n\"\n",
    "           result += f\"X - Mean: {stats['mean_x']:.3f}, Std: {stats['std_x']:.3f}n\"\n",
    "           result += f\"Y - Mean: {stats['mean_y']:.3f}, Std: {stats['std_y']:.3f}n\"\n",
    "           result += f\"Correlation: {stats['correlation']:.3f}n\"\n",
    "           result += f\"nüìà Visualization displayed above!\"\n",
    "          \n",
    "       except Exception as e:\n",
    "           result = f\"‚ùå Data analysis error: {str(e)}\"\n",
    "      \n",
    "       return [types.TextContent(type=\"text\", text=result)]\n",
    "  \n",
    "   async def _code_execution(self, language: str, task: str) -> List[types.TextContent]:\n",
    "       \"\"\"Handle code generation/execution\"\"\"\n",
    "       try:\n",
    "           if language.lower() == \"python\":\n",
    "               if \"fibonacci\" in task.lower():\n",
    "                   code = '''def fibonacci(n):\n",
    "   \"\"\"Generate fibonacci sequence up to n terms\"\"\"\n",
    "   if n <= 0:\n",
    "       return []\n",
    "   elif n == 1:\n",
    "       return [0]\n",
    "   elif n == 2:\n",
    "       return [0, 1]\n",
    "  \n",
    "   fib = [0, 1]\n",
    "   for i in range(2, n):\n",
    "       fib.append(fib[i-1] + fib[i-2])\n",
    "   return fib\n",
    "\n",
    "\n",
    "# Example usage\n",
    "print(\"First 10 fibonacci numbers:\", fibonacci(10))'''\n",
    "                  \n",
    "               elif \"sort\" in task.lower():\n",
    "                   code = '''def quicksort(arr):\n",
    "   \"\"\"Quick sort implementation\"\"\"\n",
    "\n",
    "\n",
    "def main():\n",
    "   \"\"\"Main function for {task}\"\"\"\n",
    "   print(\"Implementing: {task}\")\n",
    "   # Add your implementation here\n",
    "   pass\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "   main()'''\n",
    "              \n",
    "               result = f\"üíª Python Code for '{task}':nn```pythonn{code}n```\"\n",
    "              \n",
    "               if \"fibonacci\" in task.lower():\n",
    "                   try:\n",
    "                       exec(code)\n",
    "                       result += \"nn‚úÖ Code executed successfully!\"\n",
    "                   except Exception as exec_error:\n",
    "                       result += f\"nn‚ö†Ô∏è Execution note: {exec_error}\"\n",
    "              \n",
    "           else:\n",
    "               result = f\"üíª Code template for {language}:nn\"\n",
    "               result += f\"// {task}n// Language: {language}n// Add your implementation here\"\n",
    "              \n",
    "       except Exception as e:\n",
    "           result = f\"‚ùå Code generation error: {str(e)}\"\n",
    "      \n",
    "       return [types.TextContent(type=\"text\", text=result)]\n",
    "  \n",
    "   async def _weather_info(self, location: str) -> List[types.TextContent]:\n",
    "       \"\"\"Get weather information\"\"\"\n",
    "       weather_data = {\n",
    "           \"temperature\": np.random.randint(15, 30),\n",
    "           \"condition\": np.random.choice([\"Sunny\", \"Cloudy\", \"Rainy\", \"Partly Cloudy\"]),\n",
    "           \"humidity\": np.random.randint(40, 80),\n",
    "           \"wind_speed\": np.random.randint(5, 25)\n",
    "       }\n",
    "      \n",
    "       result = f\"üå§Ô∏è Weather for {location}:n\"\n",
    "       result += f\"Temperature: {weather_data['temperature']}¬∞Cn\"\n",
    "       result += f\"Condition: {weather_data['condition']}n\"\n",
    "       result += f\"Humidity: {weather_data['humidity']}%n\"\n",
    "       result += f\"Wind Speed: {weather_data['wind_speed']} km/hn\"\n",
    "       result += f\"nüìù Note: This is simulated data. For real weather, use a weather API service.\"\n",
    "      \n",
    "       return [types.TextContent(type=\"text\", text=result)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bfdb254",
   "metadata": {},
   "source": [
    "### We define an MCPAgent that wires Gemini to our MCP tool server and maintains conversation history, enabling us to reason, decide on a tool, execute it, and synthesize the result. We fetch the Gemini API key, configure the model, and in process_request, we prompt Gemini to choose a tool (or answer directly), run the selected tool asynchronously, and compose a final response grounded in the tool output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de50913",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MCPAgent:\n",
    "   \"\"\"AI Agent using MCP (Model Context Protocol)\"\"\"\n",
    "  \n",
    "   def __init__(self, gemini_api_key: Optional[str] = None):\n",
    "       self.gemini_api_key = gemini_api_key or self._get_api_key()\n",
    "       self.mcp_server = MCPToolServer()\n",
    "       self.conversation_history = []\n",
    "      \n",
    "       if self.gemini_api_key:\n",
    "           genai.configure(api_key=self.gemini_api_key)\n",
    "           self.model = genai.GenerativeModel('gemini-1.5-flash')\n",
    "           print(\"‚úÖ MCP Agent initialized with Gemini!\")\n",
    "       else:\n",
    "           self.model = None\n",
    "           print(\"‚ö†Ô∏è MCP Agent initialized without Gemini (limited functionality)\")\n",
    "  \n",
    "   def _get_api_key(self) -> Optional[str]:\n",
    "       \"\"\"Get Gemini API key\"\"\"\n",
    "       api_key = os.environ.get('GEMINI_API_KEY')\n",
    "       if not api_key:\n",
    "           print(\"üìù Get your free API key from: https://makersuite.google.com/app/apikey\")\n",
    "           api_key = input(\"Enter your Gemini API key (or press Enter to skip): \").strip()\n",
    "       return api_key if api_key else None\n",
    "  \n",
    "   async def process_request(self, user_input: str) -> str:\n",
    "       \"\"\"Process user request using MCP tools and Gemini\"\"\"\n",
    "       self.conversation_history.append({\"role\": \"user\", \"content\": user_input})\n",
    "      \n",
    "       available_tools = await self.mcp_server.list_tools()\n",
    "       tool_descriptions = \"n\".join([f\"- {tool.name}: {tool.description}\" for tool in available_tools])\n",
    "      \n",
    "       if self.model:\n",
    "           analysis_prompt = f\"\"\"\n",
    "           User request: \"{user_input}\"\n",
    "          \n",
    "           Available MCP tools:\n",
    "           {tool_descriptions}\n",
    "          \n",
    "           Should I use a tool for this request? If yes, specify:\n",
    "           1. Tool name (exact match)\n",
    "           2. Arguments as JSON\n",
    "          \n",
    "           If no tool needed, respond with \"NO_TOOL\".\n",
    "          \n",
    "           Format: TOOL_NAME|{{\"argument\": \"value\"}}\n",
    "           \"\"\"\n",
    "          \n",
    "           analysis = self.model.generate_content(analysis_prompt).text.strip()\n",
    "          \n",
    "           if analysis != \"NO_TOOL\" and \"|\" in analysis:\n",
    "               try:\n",
    "                   tool_name, args_json = analysis.split(\"|\", 1)\n",
    "                   tool_name = tool_name.strip()\n",
    "                   arguments = json.loads(args_json)\n",
    "                  \n",
    "                   tool_results = await self.mcp_server.call_tool(tool_name, arguments)\n",
    "                   tool_output = \"n\".join([content.text for content in tool_results])\n",
    "                  \n",
    "                   final_prompt = f\"\"\"\n",
    "                   User asked: \"{user_input}\"\n",
    "                  \n",
    "                   I used the {tool_name} tool and got this result:\n",
    "                   {tool_output}\n",
    "                  \n",
    "                   Please provide a helpful response that incorporates this information.\n",
    "                   \"\"\"\n",
    "                  \n",
    "                   response = self.model.generate_content(final_prompt).text\n",
    "                  \n",
    "               except Exception as e:\n",
    "                   response = f\"‚ùå Error using MCP tool: {str(e)}nnLet me help you directly instead.n\"\n",
    "                   response += self.model.generate_content(user_input).text\n",
    "           else:\n",
    "               response = self.model.generate_content(user_input).text\n",
    "       else:\n",
    "           response = f\"ü§ñ MCP Agent received: {user_input}n\"\n",
    "           response += \"Available tools: \" + \", \".join([tool.name for tool in available_tools])\n",
    "           response += \"nüí° Configure Gemini API for full functionality!\"\n",
    "      \n",
    "       self.conversation_history.append({\"role\": \"assistant\", \"content\": response})\n",
    "       return response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd40252c",
   "metadata": {},
   "source": [
    "### We run a scripted demo that initializes MCPAgent, executes a suite of representative queries, and prints Gemini-driven, tool-augmented responses with short pauses between runs. We then drop into an interactive loop where we can list tools, send arbitrary prompts, and observe end-to-end MCP orchestration, before printing a concise recap of the concepts covered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661e415a",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def run_mcp_demo():\n",
    "   \"\"\"Run comprehensive MCP Agent demo\"\"\"\n",
    "   print(\"üöÄ MCP Agent Demo Starting!\")\n",
    "   print(\"=\" * 50)\n",
    "  \n",
    "   agent = MCPAgent()\n",
    "  \n",
    "   demo_queries = [\n",
    "       \"Search for information about machine learning\",\n",
    "       \"Create a data visualization with sine wave analysis\",\n",
    "       \"What's the weather like in New York?\",\n",
    "       \"Explain how artificial intelligence works\"\n",
    "   ]\n",
    "  \n",
    "   print(\"nüß™ Running MCP Tool Demonstrations:\")\n",
    "   print(\"-\" * 40)\n",
    "  \n",
    "   for i, query in enumerate(demo_queries, 1):\n",
    "       print(f\"nüìù Query {i}: {query}\")\n",
    "       print(\"-\" * 30)\n",
    "      \n",
    "       response = await agent.process_request(query)\n",
    "       print(response)\n",
    "      \n",
    "       if i < len(demo_queries):\n",
    "           print(\"n‚è≥ Next demo in 3 seconds...\")\n",
    "           await asyncio.sleep(3)\n",
    "  \n",
    "   print(\"n‚úÖ MCP Demo completed!\")\n",
    "   return agent\n",
    "\n",
    "\n",
    "async def interactive_mcp_mode(agent: MCPAgent):\n",
    "   \"\"\"Interactive mode with MCP agent\"\"\"\n",
    "   print(\"nüí¨ Interactive MCP Mode!\")\n",
    "   print(\"Type 'quit' to exit, 'tools' to see available MCP tools\")\n",
    "  \n",
    "   while True:\n",
    "       try:\n",
    "           user_input = input(\"nüó£Ô∏è You: \").strip()\n",
    "          \n",
    "           if user_input.lower() == 'quit':\n",
    "               print(\"üëã Goodbye!\")\n",
    "               break\n",
    "           elif user_input.lower() == 'tools':\n",
    "               tools = await agent.mcp_server.list_tools()\n",
    "               print(\"nüõ†Ô∏è Available MCP Tools:\")\n",
    "               for tool in tools:\n",
    "                   print(f\"  - {tool.name}: {tool.description}\")\n",
    "               continue\n",
    "           elif not user_input:\n",
    "               continue\n",
    "          \n",
    "           response = await agent.process_request(user_input)\n",
    "           print(f\"nü§ñ MCP Agent: {response}\")\n",
    "          \n",
    "       except KeyboardInterrupt:\n",
    "           print(\"nüëã Goodbye!\")\n",
    "           break\n",
    "       except Exception as e:\n",
    "           print(f\"‚ùå Error: {str(e)}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "   print(\"üéØ Advanced AI Agent with MCP (Model Context Protocol)\")\n",
    "   print(\"Built for Google Colab with Gemini API integration\")\n",
    "   print(\"=\" * 60)\n",
    "  \n",
    "   agent = asyncio.run(run_mcp_demo())\n",
    "  \n",
    "   asyncio.run(interactive_mcp_mode(agent))\n",
    "  \n",
    "   print(\"nüìö MCP Tutorial Complete!\")\n",
    "   print(\"nüîç What you learned:\")\n",
    "   print(\"‚úÖ How to implement MCP (Model Context Protocol) tools\")\n",
    "   print(\"‚úÖ Tool registration and discovery\")\n",
    "   print(\"‚úÖ Structured tool calling with arguments\")\n",
    "   print(\"‚úÖ Integration between MCP tools and Gemini AI\")\n",
    "   print(\"‚úÖ Async tool execution and response handling\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd17d63c",
   "metadata": {},
   "source": [
    "### In conclusion, we now have a comprehensive MCP agent that dynamically decides when to use external tools and how to merge their outputs into meaningful responses. We validate the agent across multiple queries, showcasing its ability to search, analyze, generate, and simulate real-world interactions with Gemini as the reasoning engine. By combining structured MCP protocols with the flexibility of Gemini, we create a template for building powerful AI systems that are both interactive and technically grounded."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
